---
---

@string{aps = {American Physical Society,}}

@article{clip-illusion,
  img={/assets/img/vasarely.png},
  title={Big Vision Language Model is Capable of Capturing Optical Illusions},
  author={Phuc Ngo, Swami Sankaranarayanan, and Phillip Isola},
  abstract={Recent big machine learning models have achieved impressive performance while showing some shared similarities with human biology. In this work, we pose the question of whether big vision language models, specifically, CLIP, are able to capture optical illusion which is tightened to human biology and perception. We measure the effect by presenting a variety of illusions in the form of images and texts to CLIP and observing how the model’s classification score changes under different conditions of the illusion. Our results show that CLIP is able to capture different types of illusions like lightness illusion and geometrical illusion. We also propose a way to calibrate CLIP score to reduce biases.},
  website={https://jerryngo.com/clip-illusion/},
  year={2021}
}

@article{aug_eval,
  img={/assets/img/projects/aug_eval.png},
  title={The Effect Of Data Augmentation on Deep Representations},
  author={Phuc Ngo, Dimitris Tsipras, Saachi Jain and Aleksander Mądry},
  abstract={Data augmentation is a simple and common technique that increases the model’s robustness to class-preserving transformations. However, our understanding of how data augmentation affects deep representations is limited. In this work, we attempt to study this further and hypothesize two mechanisms that could happen. The earlier layers of the model could map augmented inputs to similar representations to the standard inputs counterpart. Or, the model could use an entirely different set of prediction rules to classify augmented samples. To test the hypothesis, we trained standard and augmented models to analyze the similarity between their predictions and representations. Our results suggest data augmentation has a range of behavior on deep representations. Depending on the severity of the augmentation, models can vary between learning invariance or learning entirely separate augmented subpopulations.},
  poster={aug_eval_poster.pdf},
  slides={aug_eval_slide.pdf},
  year={2021}
}

@article{2048,
  img={/assets/img/projects/2048_70.gif},
  title={An Application of NEAT and HyperNEAT in Solving A Sliding Tile Puzzle},
  author={Phuc Ngo, Mehmet Dik},
  abstract={Neuroevolution is a set of algorithms that use evolutionary algorithms to optimize neural networks without much domain knowledge. We analyze Neuroevolution of Augmented Topologies (NEAT) and its extension HyperNeat in this paper. NEAT evolves both the topology and weight values of a network along with novel ideas of applying speciation, tracking genes, and evolving from simple structures. HyperNEAT uses similar techniques to evolve networks but instead of using direct graph encoding as in NEAT, it uses indirect graph encoding. We use a stochastic single-player game, 2048, as the benchmark problem to compare two algorithms’ performance. Even though the game is simple, it has the random factor that may pose a challenge in finding a strategy to achieve a high score. The paper analyzes the strategy and the performance of NEAT and HyperNEAT in 2048 with different parameter settings. Furthermore, code and future work are specified at the end of the paper.},
  pdf={2048.pdf},
  slides={2048_slide.pdf},
  year={2021}
}
